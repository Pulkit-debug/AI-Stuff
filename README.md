<h3> You only need embedding_client.py, embedding_service.py and smart-rag-ui.py to run the setup </h3>

<h4> Other files are just for testing purposes </h4>

<h4> index-local is for if you want to run the llm on your local machine it uses ollama </h4>

<h5> obedient-gemini is basically the same smart-rag-ui but without ui so it works in terminal </h5>

